# Project Notes

# Glossary

- *constant folding*: recognising and evaluating constant values at
  compile time to avoid computing them at runtime.

    e.g.: (debug == false) -> false

- *constant propagation*: substituting the values of known constants
  at compile time.

    e.g.: x = 5
          y = x -> y = 5

- *dead code elimination*: eliminating code that does not need to be
  executed / is never executed.

- *fixed-point algorithm*: an algorithm which iterates over a data
  structure, modifying it until it reaches a stable state.

- *backward data-flow*: data-flow which operates on a node's
  **successors** - it moves backward along the graph's edges.

- *forward data-flow*: data-flow which operates on a node's
  predecessors - it flows along the graph's edges.

- *postorder evaluation*: visit as many of the node's children as
  possible before visiting the node.

- *reverse-postorder evaluation*: visit as many of the node's
  predecessors as possible before visiting the node.

- *control-flow graph*: a directed graph which represents the
  execution paths of a program.

- *flow insensitive*: a data-flow which ignores control flow inside
  procedures.

- *maximal SAA form*: the SSA form which contains a ϕ-function for
  every join point. This usually includes more names / ϕ-functions
  than necessary.

- *dominance frontier*: the set of nodes at which a block b's
  *dominance* ends. (see C&T, p. 499)

## Data-Flows

- *dominance*: for a CFG with entry node b0, node bi dominates bj if
  bi lies on every path from b0 to bj.

- *reaching definitions*: the definitions of variable(s) which reach a
  certain point in a program's execution.

- *liveness analysis*: a variable v is alive at point p if there
  exists a path from p to a use of v along which v is not redefined
  i.e. the value of v at p will be used later. (see C&T, 8.6)

    - *uninitialized variables*: perform liveness analysis. All the
      variables in LiveOut(n0) where n0 is the entry to the CFG are
      unitialized, as there is no point in the CFG at which those
      variables are defined (and thus killed). This misses variables
      declared outside the current scope and variables which are
      unitialised in a use on a path which will never be taken. (see
      C&T, p. 449)

    - *register allocation*: allocate registers to live variables.

    - *useless stores*: a variable which is not live does not need to
      be stored.

- *available expressions*: the set of expressions whose evaluation is
  already stored in a variable.

    e.g.: x = y * z
    y = 2 * (y * z) <-- (y*z) is available here as x

- *anticipable expressions*: an expression e is *anticipable* at the
  exit of block b if it is evaluated and subsequently used along every
  path leaving b, and evalulating e at the end of b would produce the
  same result as evaluating e along each of those paths.

    - *code motion*: used to decrease the execution time and to shrink
      the size of compiled code.


### SSA Forms

 - *maximal SSA form* inserts a ϕ-function at any point where two
   definitions of any name meet. This is the maxmimum number of
   ϕ-functions necessary for SSA form and is generated by the naive
   algorithm. It can cause issues with some forms of analysis, as
   information about definitions can be lost.

    e.g.: xj <- ϕ(xi,xi) renames xi, but this is unnecessary and will
    cause information about xi not to be propagated.

 - *minimal SSA form* meets the *minimum requirements* for SSA
   form. It adds a ϕ-function at any join point where two distinct
   definitions of any name meet. This is the minimum number of
   ϕ-functions required for SSA form. This is achieved using the
   dominance frontiers of a graph to place ϕ-functions.

 - *pruned SSA form* examines the LiveOut sets to avoid adding dead
   ϕ-functions. Removes the most ϕ-functions. Derived from *minimal SSA
   form*.

 - *semi-pruned SSA form* examines the UEVar sets to avoid adding
   unnecessary ϕ-functions. More efficient than *pruned SSA form* but
   misses some functions which could be removed (hence *semi-pruned*).

 - *global names*: the set of variable names which are live across at
   least one edge in the CFG, i.e. they are referenced in multiple
   blocks.

 - *swap problem*: the swap problem occurs when


# Notes

## Halting

Algorithm will halt when there are finite sets and each computation
can only increase the number of names in the set. Set size increases
*monotonically* - e.g. in LiveOut, VarKill is the only mechanism for
removing a name from the set and its value does not change.

Same for when set size decreases monotonically - e.g. in the case of
Dom, there is a fixed size set (must be at least 1 node and no larger
than K for K nodes). The set either shrinks or stays the same size.

With both cases, since there is a fixed size and the sets increase
monotonically, there MUST be a point at which the sets stop changing.

Finite descending chain property: combination of monotonicity and
bounded size.

## Safety-First Approach

Always take the "safe" approach - an optimisation must not modify the
output of a program in any way, including throwing errors. If there is
a risk of modification, do not perform the optimisation.

This is also true for compiler warnings that are generated with
data-flow analysis. For example, given a CFG which calls a subroutine
which is not visible, assume that any variable passed in is modified
and that any variable passed in is used. This is safe as it represents
the worst-case behaviour. (C&T, p. 450)

## Evaluation Order

RPO is the best order for iterative algorithms. For a backward
data-flow, you should compute reverse-postorder for the REVERSE CFG
(the CFG with its edges reversed). There exist different RPO
orderings, but to the iterative algorithm they are equivalent.

## Static Single-Assignment Form

Assigns a unique name to each definition / assignment to a
variable. Allows you to track which values of a variable propagate
where. Numbers variables based on the block they appear in, uses phi
functions to decide which is used where paths meet.

ϕ(x1,x2,...xn) = select from x1,x2,...,xn depending upon which path
was taken. xs are ordered by the branch they came from, left - right.

When entering the block, all ϕ-functions get evaluated concurrently
(in any order).

Each join/meet has a ϕ-function.

### Rules of SSA Form

 1. Each definition creates a unique variable name.

 2. Each use refers to a single definition.

### Converting to SSA Form

 1. At the start of each block which has multiple predecessors, insert
    a ϕ-function like y <- ϕ(y,y) for every y that the block defines or
    uses.

 2. Rename all variables (including those assigned to ϕ-functions).

This creates the *maximal SSA form*.

### Semi-pruned SSA Form

 1. Calculate the *dominance frontier* for each node in the CFG (C&T,
    p. 499).

    a) A definition of x in block b forces a ϕ-function at every node
       in DF(b). This may force more insertions, given that a
       ϕ-function in a block is itself a definition of x.

 2. Similar to liveness analysis: take the union of all
    upwards-exposed variable sets in the CFG. These are *global
    names*. We only need to add ϕ-functions for variables which are
    *global names*. (C&T, p. 500)

### Converting from SSA Form

Converting from SSA form isn't as simple as dropping the subscripts
from variable names **if transformations have occurred** (see C&T,
p. 510).

We can keep the SSA namespace and insert copy instructions at the end
of the predecessors of a block containing ϕ-functions, then remove the
ϕ-functions from that block.

We can't always add copies to the predecessor of a block: for example,
given a node n containing ϕ-functions and its successor m which has
multiple successors, adding a copy operation to m will assign that
variable in all of its successors, not just n.  To avoid this, we can
split the edge between m and n and add the copy operation in the new
block.

#### The Lost-Copy Problem

Sometimes it's inefficient to split a critical edge. In these cases,
we need to copy to a temporary variable in the predecessor and rewrite
subsequent uses to refer to the temporary variable (see C&T, p. 512).

#### The Swap Problem

The swap problem occurs when a ϕ-function has inputs which depend on
the output of previous ϕ-functions, since ϕ-functions can be executed
in any order. To solve this, we need to find dependencies between
ϕ-functions and insert a copy to a temporary variable.


## Algorithms for Data-Flow Analysis

## Iterative

Fixed-point algorithm which computes sets for each node in a given
order, until no changes occur.

### Iterative Dom Framework

For calculating Dominators only: Since the iterative algorithm for Dom
only performs a pairwise intersection between Dom sets (rather than
several sets), we can use the algorithm from C&T, p. 532 to compute
these in a more efficient manner.

## Structural

For reducible graphs only: reduces the graph to a single node,
aggregating information, then expands the graph back to its original
state, assigning the correct sets to each node.

### Test for Reducibility

When calculating the IDom set using the iterative IDom algorithm (C&T
p. 532), if the algorithm takes more than 2 passes the graph is
irreducible.


# Potential Software Features

- Choice of forward/backward data-flow

- Choice of data sets (Kill, UE, Gen etc.) over various domains

- Set the initial condition for sets

- Assembly-like language for defining programs.

- Display of CFG (initially tables).

- Display statistics - number of passes, etc.

- Allow different evaluation orders / use of a working set

- SSA form

- Inter-procedural data-flow analysis

- Analysis of reducibility: different algorithms for data-flow analysis
